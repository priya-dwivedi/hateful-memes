{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1627568776785,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"5i7JbvU1NC5j","outputId":"33caf188-9406-4697-c926-09c9c30125a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9179,"status":"ok","timestamp":1627568786178,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"gGwLUaUgSL9n","outputId":"2fdd3111-6de9-45ce-e023-f345e12d1be0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers\u003c0.11,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.61.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12-\u003etransformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers) (2.4.7)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.5.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers) (1.0.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: huggingface-hub\u003c0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: pyarrow!=4.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: fsspec\u003e=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n","Requirement already satisfied: tqdm\u003e=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.61.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets) (3.7.4.3)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003edatasets) (2.4.7)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2021.5.30)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (1.24.3)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003edatasets) (3.5.0)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2018.9)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2.8.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003edatasets) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.61.2)\n"]}],"source":["! pip install transformers\n","! pip install datasets \n","! pip install --upgrade tqdm"]},{"cell_type":"markdown","metadata":{"id":"yMzk0W2H_3rB"},"source":["!pip uninstall -y torch\n","!pip install torch==1.7.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3016,"status":"ok","timestamp":1627568789186,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"DJ5PiuN_4SD4","outputId":"50e3c563-004e-4059-bde8-ea67981964c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch-lightning==1.3.8 in /usr/local/lib/python3.7/dist-packages (1.3.8)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,\u003e=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (2021.7.0)\n","Requirement already satisfied: torchmetrics\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (0.4.1)\n","Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (0.3.0)\n","Requirement already satisfied: future\u003e=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (0.18.2)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (1.19.5)\n","Requirement already satisfied: packaging\u003e=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (21.0)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (4.61.2)\n","Requirement already satisfied: tensorboard!=2.5.0,\u003e=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (2.4.1)\n","Requirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (7.1.2)\n","Requirement already satisfied: torch\u003e=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (1.9.0+cu102)\n","Requirement already satisfied: PyYAML\u003c=5.4.1,\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.8) (5.4.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (3.7.4.post0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (2.23.0)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=17.0-\u003epytorch-lightning==1.3.8) (2.4.7)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (0.4.4)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (3.3.4)\n","Requirement already satisfied: protobuf\u003e=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.8.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.0.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (0.36.2)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (57.2.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (0.12.0)\n","Requirement already satisfied: google-auth\u003c2,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.32.1)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.34.1)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.15.0)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (4.2.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (0.2.8)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c2,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (4.7.2)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (4.6.1)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c2,\u003e=1.6.3-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (0.4.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (1.24.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=1.4-\u003epytorch-lightning==1.3.8) (3.7.4.3)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (1.6.3)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (5.1.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (21.2.0)\n","Requirement already satisfied: async-timeout\u003c4.0,\u003e=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.3.8) (3.0.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard!=2.5.0,\u003e=2.2.0-\u003epytorch-lightning==1.3.8) (3.5.0)\n"]}],"source":["!pip install pytorch-lightning==1.3.8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11222,"status":"ok","timestamp":1627568800405,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"Xy4zMdnsM3dw","outputId":"f155a6f5-b236-4450-c800-bd5c95535a00"},"outputs":[{"name":"stdout","output_type":"stream","text":["replace hateful_memes/dev_unseen.jsonl? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}],"source":["# !unzip -qq /content/drive/MyDrive/Hateful_Memes/hateful_memes.zip\n","# !cp -r /content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/hateful_memes /content/\n","# !unzip -qq /content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/AugLyEdHateful_memes.zip\n","!unzip -qq /content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/augLyEdHateful_memes.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1627568800753,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"WsBkc_dbAcfh","outputId":"c29051c9-a8b8-4581-ecc9-de22010fa957"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.9.0+cu102'"]},"execution_count":5,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EN8lH9xXSvs5"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cjLM5dPzzaV"},"outputs":[],"source":["import os\n","import shutil\n","\n","dirpath = '/content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint'\n","# No need to deleted the previous checkpoints\n","# if os.path.exists(dirpath) and os.path.isdir(dirpath):\n","#     shutil.rmtree(dirpath)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1627568800755,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"k7nWls_fSzMi","outputId":"be1d8925-0c95-4b86-b5dd-e3d695216bb4"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eimg\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e42953\u003c/td\u003e\n","      \u003ctd\u003eimg/42953.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eits their character not their color that matters\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e23058\u003c/td\u003e\n","      \u003ctd\u003eimg/23058.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003edon't be afraid to love again everyone is not ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e13894\u003c/td\u003e\n","      \u003ctd\u003eimg/13894.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eputting bows on your pet\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e37408\u003c/td\u003e\n","      \u003ctd\u003eimg/37408.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ei love everything and everybody! except for sq...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e82403\u003c/td\u003e\n","      \u003ctd\u003eimg/82403.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eeverybody loves chocolate chip cookies, even h...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      id  ...                                               text\n","0  42953  ...   its their character not their color that matters\n","1  23058  ...  don't be afraid to love again everyone is not ...\n","2  13894  ...                           putting bows on your pet\n","3  37408  ...  i love everything and everybody! except for sq...\n","4  82403  ...  everybody loves chocolate chip cookies, even h...\n","\n","[5 rows x 4 columns]"]},"execution_count":8,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train = pd.read_json('hateful_memes/train.jsonl', lines=True)\n","df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1627568800755,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"TQ1ODk-5OO5h","outputId":"48157fba-b7b8-460b-dfb6-aecfc7ce3ce3"},"outputs":[{"data":{"text/plain":["0    5481\n","1    3019\n","Name: label, dtype: int64"]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1627568800755,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"XSaxQs7nNYyK","outputId":"526dac3d-d8e9-407b-bb51-b81425f3304e"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eimg\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e8291\u003c/td\u003e\n","      \u003ctd\u003eimg/08291.png\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003ewhite people is this a shooting range\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e46971\u003c/td\u003e\n","      \u003ctd\u003eimg/46971.png\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003ebravery at its finest\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e3745\u003c/td\u003e\n","      \u003ctd\u003eimg/03745.png\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eyour order comes to $37.50 and your white priv...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e83745\u003c/td\u003e\n","      \u003ctd\u003eimg/83745.png\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eit is time.. to send these parasites back to t...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e80243\u003c/td\u003e\n","      \u003ctd\u003eimg/80243.png\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003emississippi wind chime\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      id  ...                                               text\n","0   8291  ...              white people is this a shooting range\n","1  46971  ...                              bravery at its finest\n","2   3745  ...  your order comes to $37.50 and your white priv...\n","3  83745  ...  it is time.. to send these parasites back to t...\n","4  80243  ...                             mississippi wind chime\n","\n","[5 rows x 4 columns]"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["val_seen = pd.read_json('hateful_memes/dev_seen.jsonl', lines=True)\n","val_unseen = pd.read_json('hateful_memes/dev_unseen.jsonl', lines=True)\n","df_val = pd.concat([val_seen, val_unseen],axis=0)\n","df_val.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1627568800937,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"-tTMcN4tNXAq","outputId":"c37b2abf-5329-4a65-9b76-4f3f09fd4d4e"},"outputs":[{"data":{"text/plain":["((8500, 4), (1040, 4), (3000, 4))"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["test_seen = pd.read_json('hateful_memes/test_seen.jsonl', lines=True)\n","test_unseen = pd.read_json('hateful_memes/test_unseen.jsonl', lines=True)\n","df_test = pd.concat([test_seen, test_unseen],axis=0)\n","df_train.shape, df_val.shape, df_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1627568800937,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"SNZioUGONoFk","outputId":"b6988c62-a77b-458d-baf9-ae660ebb790f"},"outputs":[{"data":{"text/plain":["0    593\n","1    447\n","Name: label, dtype: int64"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_val.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1627568800937,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"SSDdEPzXN8rz","outputId":"08996cad-a03e-4f87-9244-cf83a5d64c16"},"outputs":[{"data":{"text/plain":["0    1760\n","1    1240\n","Name: label, dtype: int64"]},"execution_count":13,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_test.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1627568800938,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"DCqW-BBgO1w5","outputId":"dd3e867c-af57-4bee-9f9c-a71f3eac9e62"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eimg\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e42953\u003c/td\u003e\n","      \u003ctd\u003eimg/42953.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eits their character not their color that matters\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e23058\u003c/td\u003e\n","      \u003ctd\u003eimg/23058.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003edon't be afraid to love again everyone is not ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e13894\u003c/td\u003e\n","      \u003ctd\u003eimg/13894.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eputting bows on your pet\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e37408\u003c/td\u003e\n","      \u003ctd\u003eimg/37408.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ei love everything and everybody! except for sq...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e82403\u003c/td\u003e\n","      \u003ctd\u003eimg/82403.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eeverybody loves chocolate chip cookies, even h...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      id  ...                                               text\n","0  42953  ...   its their character not their color that matters\n","1  23058  ...  don't be afraid to love again everyone is not ...\n","2  13894  ...                           putting bows on your pet\n","3  37408  ...  i love everything and everybody! except for sq...\n","4  82403  ...  everybody loves chocolate chip cookies, even h...\n","\n","[5 rows x 4 columns]"]},"execution_count":14,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1627568800938,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"a_192_dTP5Sn","outputId":"78247a9e-0b8f-4442-8b40-4cf6c183abb7"},"outputs":[{"data":{"text/plain":["count    8500.000000\n","mean       11.742588\n","std         6.877021\n","min         1.000000\n","25%         7.000000\n","50%        10.000000\n","75%        15.000000\n","max        70.000000\n","Name: text_len, dtype: float64"]},"execution_count":15,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train['text_len'] = df_train['text'].str.split().str.len()\n","df_train['text_len'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1627568800938,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"xmFf_MUKkAFD","outputId":"2a4a62cd-80d9-48c5-84a1-432de019e3ef"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eimg\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003etext_len\u003c/th\u003e\n","      \u003cth\u003eidx\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e42953\u003c/td\u003e\n","      \u003ctd\u003eimg/42953.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eits their character not their color that matters\u003c/td\u003e\n","      \u003ctd\u003e8\u003c/td\u003e\n","      \u003ctd\u003e42953\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e23058\u003c/td\u003e\n","      \u003ctd\u003eimg/23058.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003edon't be afraid to love again everyone is not ...\u003c/td\u003e\n","      \u003ctd\u003e12\u003c/td\u003e\n","      \u003ctd\u003e23058\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e13894\u003c/td\u003e\n","      \u003ctd\u003eimg/13894.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eputting bows on your pet\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e13894\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e37408\u003c/td\u003e\n","      \u003ctd\u003eimg/37408.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003ei love everything and everybody! except for sq...\u003c/td\u003e\n","      \u003ctd\u003e11\u003c/td\u003e\n","      \u003ctd\u003e37408\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e82403\u003c/td\u003e\n","      \u003ctd\u003eimg/82403.png\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eeverybody loves chocolate chip cookies, even h...\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e82403\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["      id            img  ...  text_len    idx\n","0  42953  img/42953.png  ...         8  42953\n","1  23058  img/23058.png  ...        12  23058\n","2  13894  img/13894.png  ...         5  13894\n","3  37408  img/37408.png  ...        11  37408\n","4  82403  img/82403.png  ...         7  82403\n","\n","[5 rows x 6 columns]"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train['idx'] = df_train['id'].astype(str).str.zfill(5)\n","df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7aHKHGRkNG2"},"outputs":[],"source":["df_val['idx'] = df_val['id'].astype(str).str.zfill(5)\n","df_test['idx'] = df_test['id'].astype(str).str.zfill(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1627568800939,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"_M8zN1groWmC","outputId":"3f7a4d23-ccf9-4db7-d0d6-3ddea518c600"},"outputs":[{"data":{"text/plain":["((8500, 6), (1040, 5))"]},"execution_count":18,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train.shape, df_val.shape"]},{"cell_type":"markdown","metadata":{"id":"8_ieiNwrLUzt"},"source":["## Compute Class Weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1627568801479,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"HjGXoyRtLXuY","outputId":"cc1e3587-aed9-44e9-892f-c4b5a02c7f56"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.77540595 1.40775091]\n"]}],"source":["from sklearn.utils import class_weight\n","y_train = df_train[\"label\"].values.tolist()\n","class_weights = class_weight.compute_class_weight('balanced',\n","                                                 np.unique(y_train),\n","                                                 y_train)\n","print(class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1627568801480,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"SgUHGzZFP4fG","outputId":"523f0124-2637-4549-e5b0-fc0064b973ee"},"outputs":[{"data":{"text/plain":["0    5481\n","1    3019\n","Name: label, dtype: int64"]},"execution_count":20,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df_train.label.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"BrmDPEtUe7Hm"},"source":["## Load as a dataset"]},{"cell_type":"markdown","metadata":{"id":"UvtF2j5CaPn4"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1627568802297,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"15HVpWiKPSkH","outputId":"30144f01-c96c-4d04-bbdf-e9619a86d0b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['accuracy', 'bertscore', 'bleu', 'bleurt', 'cer', 'comet', 'coval', 'cuad', 'f1', 'gleu', 'glue', 'indic_glue', 'matthews_correlation', 'meteor', 'pearsonr', 'precision', 'recall', 'rouge', 'sacrebleu', 'sari', 'seqeval', 'spearmanr', 'squad', 'squad_v2', 'super_glue', 'wer', 'wiki_split', 'xnli']\n"]}],"source":["from datasets import list_metrics, load_metric\n","metrics_list = list_metrics()\n","print(metrics_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kv4m5UAf1B3"},"outputs":[],"source":["acc_metric = load_metric('accuracy')\n","f1_metric = load_metric('f1')\n","precision_metric = load_metric('precision')\n","recall_metric = load_metric('recall')"]},{"cell_type":"markdown","metadata":{"id":"7ZD53AeagF4D"},"source":["## Create Dataset function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"olZeIJOhgDty"},"outputs":[],"source":["from transformers import BertTokenizer, VisualBertForPreTraining, AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","metadata":{"id":"EQ0oB82ISJHA"},"source":["## Load Visual Embedding features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeeChXlYk1QF"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTD_ZGsbP1qT"},"outputs":[],"source":["from transformers import ViTFeatureExtractor, ViTModel\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlJiS4aLQD1_"},"outputs":[],"source":["feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n","feature_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pIK2KYvSnh-"},"outputs":[],"source":["class HatefulMemesData(Dataset):\n","    def __init__(self, df, tokenizer, sequence_length, \n","                 print_text=False):         \n","\n","        self.sequence_length = sequence_length\n","        self.tokenizer = tokenizer\n","        self.print_text = print_text\n","\n","        texts = df[\"text\"].values.tolist()\n","        labels = df[\"label\"].values.tolist()\n","        images = df[\"img\"].values.tolist()\n","        ids =  df[\"idx\"].values.tolist()\n","\n","        self.dataset = []\n","        for i, inp in enumerate(texts):\n","            self.dataset.append({\"text\": inp, \"label\": labels[i], 'idx': ids[i], 'image': images[i]})\n","  \n","    def __len__(self):\n","        return len(self.dataset)\n","\n","\n","    def tokenize_data(self, example):\n","   \n","        idx = example['idx']\n","        idx = [idx] if isinstance(idx, str) else idx\n","        # encoded_dict = tokenizer.batch_encode_plus(example['text'], padding='max_length', max_length=max_len, truncation=True, return_tensors='pt')\n","        encoded_dict = tokenizer(example['text'], padding='max_length', max_length=self.sequence_length, truncation=True, return_tensors='pt')\n","        tokens = encoded_dict['input_ids']\n","        token_type_ids = encoded_dict['token_type_ids']\n","        attn_mask = encoded_dict['attention_mask']\n","        \n","        targets = torch.tensor(example['label']).type(torch.int64)\n","\n","        ## Get Visual Embeddings\n","        try:\n","            img = example['image']\n","            img = Image.open(os.path.join('hateful_memes', img))\n","            img = np.array(img)\n","            img = img[...,:3]\n","            inputs = feature_extractor(images=img, return_tensors=\"pt\")\n","            outputs = feature_model(**inputs.to('cuda'))\n","            visual_embeds = outputs.last_hidden_state\n","            visual_embeds = visual_embeds.cpu()\n","        except:\n","            # print(\"Error with Id: \", idx)\n","            visual_embeds = np.zeros(shape=(197, 768), dtype=float)\n","        # visual_embeds = visual_embeds.repeat(1,1,2)\n","\n","        visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n","        visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.int64)\n","\n","        inputs={\"input_ids\": tokens.squeeze(),\n","            \"attention_mask\": attn_mask.squeeze(),\n","            \"token_type_ids\": token_type_ids.squeeze(),\n","            \"visual_embeds\": visual_embeds.squeeze(),\n","            \"visual_token_type_ids\": visual_token_type_ids.squeeze(),\n","            \"visual_attention_mask\": visual_attention_mask.squeeze(),\n","            \"label\": targets.squeeze()\n","        }\n","        \n","        return inputs\n","  \n","    def __getitem__(self, index):\n","        inputs = self.tokenize_data(self.dataset[index])\n","        \n","        if self.print_text:\n","            for k in inputs.keys():\n","                print(k, inputs[k].shape, inputs[k].dtype)\n","\n","        return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5W2mYO_kLLf"},"outputs":[],"source":["dataset = HatefulMemesData(df_val, tokenizer, 50, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1627568815650,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"_lz3WbW5kUog","outputId":"87739a19-241d-4d5a-c238-8e8f538d4307"},"outputs":[{"name":"stdout","output_type":"stream","text":["input_ids torch.Size([50]) torch.int64\n","attention_mask torch.Size([50]) torch.int64\n","token_type_ids torch.Size([50]) torch.int64\n","visual_embeds torch.Size([197, 768]) torch.float32\n","visual_token_type_ids torch.Size([197]) torch.int64\n","visual_attention_mask torch.Size([197]) torch.int64\n","label torch.Size([]) torch.int64\n"]}],"source":["example1 = dataset[100]"]},{"cell_type":"markdown","metadata":{"id":"7LTa5sqUkI_J"},"source":["## Fine-Tune Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1697,"status":"ok","timestamp":1627568817346,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"DdLo_MtAkCZt","outputId":"e33bb2d1-fc4e-40d6-ac11-329cf122e62c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertTokenizer, VisualBertModel, TrainingArguments, Trainer, VisualBertConfig\n","configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n","                                                hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)\n","model = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1627568817346,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"yWcMWWgzF71h","outputId":"e402de13-5418-4beb-c880-80536747962e"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([  101,  2651,  2057,  2024,  2437, 15415, 11350,   102,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0]), 'visual_embeds': tensor([[-0.2966, -0.1574, -0.2864,  ..., -0.1282, -0.0333, -0.1209],\n","        [-0.3976, -0.1522, -0.1042,  ..., -0.0770,  0.1195, -0.0293],\n","        [-0.3948,  0.0101, -0.3677,  ..., -0.1741,  0.0610, -0.2842],\n","        ...,\n","        [-0.3196, -0.1651, -0.3165,  ...,  0.0797,  0.0650,  0.0055],\n","        [-0.3075, -0.2971, -0.1485,  ..., -0.1102, -0.0683,  0.0418],\n","        [-0.1843,  0.2635, -0.2009,  ..., -0.2818,  0.0353, -0.0666]],\n","       grad_fn=\u003cSqueezeBackward0\u003e), 'visual_token_type_ids': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1]), 'visual_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1]), 'label': tensor(1)}\n"]}],"source":["# example1 = tokenize_data(df_train.to_dict('records')[0])\n","print(example1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1627568817347,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"ou29gT0lgbv2","outputId":"2a1f10e6-ef90-41e6-d059-039413cbc8b1"},"outputs":[{"data":{"text/plain":["torch.Size([1, 50])"]},"execution_count":32,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["example1['input_ids'].unsqueeze(0).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXGtuj6f2XgR"},"outputs":[],"source":["model = model.double()"]},{"cell_type":"markdown","metadata":{"id":"j_1lUf09D91Z"},"source":["outputs = model(input_ids=example1['input_ids'].unsqueeze(0),\n","                attention_mask=example1['attention_mask'].unsqueeze(0),\n","                visual_token_type_ids=example1['visual_token_type_ids'].unsqueeze(0),\n","                token_type_ids=example1['token_type_ids'].unsqueeze(0),\n","                visual_embeds=example1['visual_embeds'].unsqueeze(0),\n","                visual_attention_mask=example1['visual_attention_mask'].unsqueeze(0),\n","                )"]},{"cell_type":"markdown","metadata":{"id":"67hOqJMSK7GX"},"source":["pooled_outputs = outputs[1]\n","print(pooled_outputs.shape)"]},{"cell_type":"markdown","metadata":{"id":"RAhhNY4y4MUa"},"source":["## Tuning using Pytorch Lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8Nh2K8j4L1g"},"outputs":[],"source":["import pytorch_lightning as pl\n","from torch.utils.data import Dataset, DataLoader\n","from pytorch_lightning.loggers import WandbLogger\n","from datasets import load_metric\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score\n","from transformers import (\n","    AdamW,\n","    VisualBertModel,\n","    get_linear_schedule_with_warmup\n",")\n","import logging\n","import argparse\n","import time\n","from torch.nn import CrossEntropyLoss\n","from sklearn.metrics import roc_auc_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpsDvM-r4L4T"},"outputs":[],"source":["# from pytorch_lightning.loggers.wandb import WandbLogger\n","import os\n","from pathlib import Path\n","from string import punctuation\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{"id":"J-hl24bz3obU"},"source":["## Look at Model Summary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1627568817726,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"i-_UouKgObfk","outputId":"23228aa8-2e42-420f-b8b8-1db5696616bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.7751, 1.4087], device='cuda:0')\n"]}],"source":["weights = [0.77510622, 1.40873991]\n","wt_tensor = torch.FloatTensor(weights).cuda()\n","print(wt_tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTSuZE5G3FNu"},"outputs":[],"source":["class VisualBERTClassifier(torch.nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        In the constructor we instantiate two nn.Linear modules and assign them as\n","        member variables.\n","        \"\"\"\n","        super(VisualBERTClassifier, self).__init__()\n","        configuration = VisualBertConfig.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre',\n","                                                hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n","        self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre', config=configuration)\n","        self.embed_cls = nn.Linear(768, 1024)\n","        # self.visualbert = VisualBertModel.from_pretrained('uclanlp/visualbert-nlvr2-coco-pre')\n","        self.num_labels = 2\n","        self.dropout = nn.Dropout(0.3)\n","        self.cls=  nn.Linear(768, self.num_labels)\n","        self.weight = torch.FloatTensor([0.77510622, 1.40873991]),\n","\n","        nSamples = [5178, 2849]\n","        normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]\n","        self.loss_fct = CrossEntropyLoss(weight=torch.FloatTensor(normedWeights))\n","        \n","    \n","    def forward(self, input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask,\n","                visual_token_type_ids, labels):\n","        \"\"\"\n","        In the forward function we accept a Tensor of input data and we must return\n","        a Tensor of output data. We can use Modules defined in the constructor as\n","        well as arbitrary operators on Tensors.\n","        \"\"\"\n","        visual_embeds_cls = self.embed_cls(visual_embeds)\n","        outputs = self.visualbert(\n","                input_ids,\n","                attention_mask=attention_mask,\n","                token_type_ids=token_type_ids,\n","                visual_embeds=visual_embeds_cls,\n","                visual_attention_mask=visual_attention_mask,\n","                visual_token_type_ids=visual_token_type_ids,\n","            )\n","        \n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.cls(pooled_output)\n","        reshaped_logits = logits.view(-1, self.num_labels)\n","\n","        loss = self.loss_fct(reshaped_logits, labels.view(-1))\n","      \n","        return loss, reshaped_logits"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2195,"status":"ok","timestamp":1627568819918,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"Q6v7whCY5Qwy","outputId":"d501d014-23a3-48b3-e13f-c8833eceb2ce"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = VisualBERTClassifier().to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1627568820094,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"jnw7jNeFyIEc","outputId":"5cc490cf-fe88-4029-fbfb-d393db5b9af3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jul 29 14:26:59 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    39W / 300W |   2341MiB / 16160MiB |     10%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"f7tblaBP7Gb_"},"source":["## Using HuggingFace Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q64H3ECW7Jq_"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","batch_size = 24\n","seq_len = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2117,"status":"ok","timestamp":1627568822210,"user":{"displayName":"Learning Notes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNwwl6qUINCU4zfd-6kgnjqgD6bMg0NNav2nzEag=s64","userId":"11895322837909450720"},"user_tz":360},"id":"DRuUBtBe8JYR","outputId":"954ec6ca-022d-475d-b8ad-9f25750e8e0b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = VisualBERTClassifier()\n","model = model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UefymyHr7Jt_"},"outputs":[],"source":["metric_name = \"auroc\"\n","\n","args = TrainingArguments(\n","    output_dir = \"drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint\",\n","    seed = 110, \n","    evaluation_strategy = \"steps\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=50,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    eval_steps = 250,\n","    save_steps = 250,\n","    fp16 = False,\n","    gradient_accumulation_steps = 2\n","\n","\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-C8d6fw7Jwh"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    acc = acc_metric.compute(predictions=predictions, references=labels)\n","    auc_score = roc_auc_score(labels, predictions)\n","    return {\"accuracy\": acc['accuracy'], \"auroc\": auc_score} "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwSU1fNp70mt"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset = HatefulMemesData(df_train,tokenizer=tokenizer, sequence_length=seq_len),\n","    eval_dataset =  HatefulMemesData(df_val,tokenizer=tokenizer, sequence_length=seq_len),\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"8c7lrnLe9lUO"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 8500\n","  Num Epochs = 50\n","  Instantaneous batch size per device = 24\n","  Total train batch size (w. parallel, distributed \u0026 accumulation) = 48\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 8850\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='8850' max='8850' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [8850/8850 8:59:07, Epoch 49/50]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","      \u003cth\u003eAccuracy\u003c/th\u003e\n","      \u003cth\u003eAuroc\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e250\u003c/td\u003e\n","      \u003ctd\u003eNo log\u003c/td\u003e\n","      \u003ctd\u003e0.700464\u003c/td\u003e\n","      \u003ctd\u003e0.567308\u003c/td\u003e\n","      \u003ctd\u003e0.538505\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e500\u003c/td\u003e\n","      \u003ctd\u003e0.680000\u003c/td\u003e\n","      \u003ctd\u003e0.734522\u003c/td\u003e\n","      \u003ctd\u003e0.544231\u003c/td\u003e\n","      \u003ctd\u003e0.554897\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e750\u003c/td\u003e\n","      \u003ctd\u003e0.680000\u003c/td\u003e\n","      \u003ctd\u003e0.827499\u003c/td\u003e\n","      \u003ctd\u003e0.600000\u003c/td\u003e\n","      \u003ctd\u003e0.585073\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1000\u003c/td\u003e\n","      \u003ctd\u003e0.455300\u003c/td\u003e\n","      \u003ctd\u003e0.806920\u003c/td\u003e\n","      \u003ctd\u003e0.613462\u003c/td\u003e\n","      \u003ctd\u003e0.599632\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1250\u003c/td\u003e\n","      \u003ctd\u003e0.455300\u003c/td\u003e\n","      \u003ctd\u003e1.156088\u003c/td\u003e\n","      \u003ctd\u003e0.627885\u003c/td\u003e\n","      \u003ctd\u003e0.606771\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1500\u003c/td\u003e\n","      \u003ctd\u003e0.223400\u003c/td\u003e\n","      \u003ctd\u003e1.292776\u003c/td\u003e\n","      \u003ctd\u003e0.644231\u003c/td\u003e\n","      \u003ctd\u003e0.635151\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e1750\u003c/td\u003e\n","      \u003ctd\u003e0.223400\u003c/td\u003e\n","      \u003ctd\u003e1.576017\u003c/td\u003e\n","      \u003ctd\u003e0.615385\u003c/td\u003e\n","      \u003ctd\u003e0.590853\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2000\u003c/td\u003e\n","      \u003ctd\u003e0.114400\u003c/td\u003e\n","      \u003ctd\u003e1.895247\u003c/td\u003e\n","      \u003ctd\u003e0.630769\u003c/td\u003e\n","      \u003ctd\u003e0.602416\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2250\u003c/td\u003e\n","      \u003ctd\u003e0.114400\u003c/td\u003e\n","      \u003ctd\u003e1.955153\u003c/td\u003e\n","      \u003ctd\u003e0.633654\u003c/td\u003e\n","      \u003ctd\u003e0.615135\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2500\u003c/td\u003e\n","      \u003ctd\u003e0.071300\u003c/td\u003e\n","      \u003ctd\u003e2.376897\u003c/td\u003e\n","      \u003ctd\u003e0.633654\u003c/td\u003e\n","      \u003ctd\u003e0.606047\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e2750\u003c/td\u003e\n","      \u003ctd\u003e0.071300\u003c/td\u003e\n","      \u003ctd\u003e2.203463\u003c/td\u003e\n","      \u003ctd\u003e0.634615\u003c/td\u003e\n","      \u003ctd\u003e0.622863\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3000\u003c/td\u003e\n","      \u003ctd\u003e0.050500\u003c/td\u003e\n","      \u003ctd\u003e2.804096\u003c/td\u003e\n","      \u003ctd\u003e0.617308\u003c/td\u003e\n","      \u003ctd\u003e0.588408\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3250\u003c/td\u003e\n","      \u003ctd\u003e0.050500\u003c/td\u003e\n","      \u003ctd\u003e2.557670\u003c/td\u003e\n","      \u003ctd\u003e0.621154\u003c/td\u003e\n","      \u003ctd\u003e0.605551\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3500\u003c/td\u003e\n","      \u003ctd\u003e0.035700\u003c/td\u003e\n","      \u003ctd\u003e2.911102\u003c/td\u003e\n","      \u003ctd\u003e0.621154\u003c/td\u003e\n","      \u003ctd\u003e0.599492\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e3750\u003c/td\u003e\n","      \u003ctd\u003e0.035700\u003c/td\u003e\n","      \u003ctd\u003e3.281651\u003c/td\u003e\n","      \u003ctd\u003e0.635577\u003c/td\u003e\n","      \u003ctd\u003e0.601675\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4000\u003c/td\u003e\n","      \u003ctd\u003e0.024400\u003c/td\u003e\n","      \u003ctd\u003e3.355340\u003c/td\u003e\n","      \u003ctd\u003e0.637500\u003c/td\u003e\n","      \u003ctd\u003e0.607492\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4250\u003c/td\u003e\n","      \u003ctd\u003e0.024400\u003c/td\u003e\n","      \u003ctd\u003e3.211192\u003c/td\u003e\n","      \u003ctd\u003e0.636538\u003c/td\u003e\n","      \u003ctd\u003e0.618215\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4500\u003c/td\u003e\n","      \u003ctd\u003e0.022200\u003c/td\u003e\n","      \u003ctd\u003e3.207808\u003c/td\u003e\n","      \u003ctd\u003e0.644231\u003c/td\u003e\n","      \u003ctd\u003e0.625512\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e4750\u003c/td\u003e\n","      \u003ctd\u003e0.022200\u003c/td\u003e\n","      \u003ctd\u003e3.422194\u003c/td\u003e\n","      \u003ctd\u003e0.638462\u003c/td\u003e\n","      \u003ctd\u003e0.619076\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5000\u003c/td\u003e\n","      \u003ctd\u003e0.013300\u003c/td\u003e\n","      \u003ctd\u003e3.741333\u003c/td\u003e\n","      \u003ctd\u003e0.630769\u003c/td\u003e\n","      \u003ctd\u003e0.602691\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5250\u003c/td\u003e\n","      \u003ctd\u003e0.013300\u003c/td\u003e\n","      \u003ctd\u003e3.560200\u003c/td\u003e\n","      \u003ctd\u003e0.619231\u003c/td\u003e\n","      \u003ctd\u003e0.598357\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5500\u003c/td\u003e\n","      \u003ctd\u003e0.017000\u003c/td\u003e\n","      \u003ctd\u003e3.456541\u003c/td\u003e\n","      \u003ctd\u003e0.624038\u003c/td\u003e\n","      \u003ctd\u003e0.599543\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e5750\u003c/td\u003e\n","      \u003ctd\u003e0.017000\u003c/td\u003e\n","      \u003ctd\u003e3.704052\u003c/td\u003e\n","      \u003ctd\u003e0.620192\u003c/td\u003e\n","      \u003ctd\u003e0.593967\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6000\u003c/td\u003e\n","      \u003ctd\u003e0.011300\u003c/td\u003e\n","      \u003ctd\u003e3.709839\u003c/td\u003e\n","      \u003ctd\u003e0.625962\u003c/td\u003e\n","      \u003ctd\u003e0.601229\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6250\u003c/td\u003e\n","      \u003ctd\u003e0.011300\u003c/td\u003e\n","      \u003ctd\u003e3.489398\u003c/td\u003e\n","      \u003ctd\u003e0.624038\u003c/td\u003e\n","      \u003ctd\u003e0.605877\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6500\u003c/td\u003e\n","      \u003ctd\u003e0.006000\u003c/td\u003e\n","      \u003ctd\u003e3.853492\u003c/td\u003e\n","      \u003ctd\u003e0.629808\u003c/td\u003e\n","      \u003ctd\u003e0.606255\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e6750\u003c/td\u003e\n","      \u003ctd\u003e0.006000\u003c/td\u003e\n","      \u003ctd\u003e3.791738\u003c/td\u003e\n","      \u003ctd\u003e0.626923\u003c/td\u003e\n","      \u003ctd\u003e0.600696\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7000\u003c/td\u003e\n","      \u003ctd\u003e0.005600\u003c/td\u003e\n","      \u003ctd\u003e3.832260\u003c/td\u003e\n","      \u003ctd\u003e0.625000\u003c/td\u003e\n","      \u003ctd\u003e0.600386\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7250\u003c/td\u003e\n","      \u003ctd\u003e0.005600\u003c/td\u003e\n","      \u003ctd\u003e4.034073\u003c/td\u003e\n","      \u003ctd\u003e0.624038\u003c/td\u003e\n","      \u003ctd\u003e0.597065\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7500\u003c/td\u003e\n","      \u003ctd\u003e0.006100\u003c/td\u003e\n","      \u003ctd\u003e3.801070\u003c/td\u003e\n","      \u003ctd\u003e0.631731\u003c/td\u003e\n","      \u003ctd\u003e0.613173\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e7750\u003c/td\u003e\n","      \u003ctd\u003e0.006100\u003c/td\u003e\n","      \u003ctd\u003e3.862844\u003c/td\u003e\n","      \u003ctd\u003e0.624038\u003c/td\u003e\n","      \u003ctd\u003e0.602022\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8000\u003c/td\u003e\n","      \u003ctd\u003e0.002100\u003c/td\u003e\n","      \u003ctd\u003e3.964432\u003c/td\u003e\n","      \u003ctd\u003e0.623077\u003c/td\u003e\n","      \u003ctd\u003e0.600352\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8250\u003c/td\u003e\n","      \u003ctd\u003e0.002100\u003c/td\u003e\n","      \u003ctd\u003e3.909158\u003c/td\u003e\n","      \u003ctd\u003e0.625962\u003c/td\u003e\n","      \u003ctd\u003e0.603983\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8500\u003c/td\u003e\n","      \u003ctd\u003e0.004100\u003c/td\u003e\n","      \u003ctd\u003e3.978961\u003c/td\u003e\n","      \u003ctd\u003e0.635577\u003c/td\u003e\n","      \u003ctd\u003e0.610487\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e8750\u003c/td\u003e\n","      \u003ctd\u003e0.004100\u003c/td\u003e\n","      \u003ctd\u003e3.954149\u003c/td\u003e\n","      \u003ctd\u003e0.634615\u003c/td\u003e\n","      \u003ctd\u003e0.610470\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-2750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-3750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-5750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-6750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-7750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8000\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8250\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8250/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8500\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n","Saving model checkpoint to drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8750\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8750/tokenizer_config.json\n","Special tokens file saved in drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-8750/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-1500 (score: 0.6351505822968185).\n"]},{"data":{"text/plain":["TrainOutput(global_step=8850, training_loss=0.09854852825234839, metrics={'train_runtime': 32351.3109, 'train_samples_per_second': 13.137, 'train_steps_per_second': 0.274, 'total_flos': 0.0, 'train_loss': 0.09854852825234839, 'epoch': 50.0})"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["## To resume from an old checkpoint, set path in resume-from\n","resume_from ='/content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/model-checkpoint/checkpoint-4250'\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NIzbDwJeY08R"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 1040\n","  Batch size = 24\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [44/44 01:03]\n","    \u003c/div\u003e\n","    "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'epoch': 50.0,\n"," 'eval_accuracy': 0.6442307692307693,\n"," 'eval_auroc': 0.6351505822968185,\n"," 'eval_loss': 1.2927756309509277,\n"," 'eval_runtime': 64.6922,\n"," 'eval_samples_per_second': 16.076,\n"," 'eval_steps_per_second': 0.68}"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0pm3hl5JY3k8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to VisualBERT_classification_model\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","tokenizer config file saved in VisualBERT_classification_model/tokenizer_config.json\n","Special tokens file saved in VisualBERT_classification_model/special_tokens_map.json\n"]}],"source":["trainer.save_model('VisualBERT_classification_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"G58y74pJY7uK"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: VisualBERT_classification_model/ (stored 0%)\n","  adding: VisualBERT_classification_model/special_tokens_map.json (deflated 40%)\n","  adding: VisualBERT_classification_model/training_args.bin (deflated 47%)\n","  adding: VisualBERT_classification_model/tokenizer_config.json (deflated 39%)\n","  adding: VisualBERT_classification_model/pytorch_model.bin (deflated 8%)\n","  adding: VisualBERT_classification_model/tokenizer.json (deflated 59%)\n","  adding: VisualBERT_classification_model/vocab.txt (deflated 53%)\n"]}],"source":["!zip -r 'VisualBERT_classification_model.zip' 'VisualBERT_classification_model'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O41GPWcFd3mJ"},"outputs":[],"source":["!mv VisualBERT_classification_model.zip /content/drive/MyDrive/studying/CS7643/CS7643Project/AugLyEd/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7hJiCXVyYn99"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"tPXnT1KPYo6a"},"source":["## Pytorch Lightning version of code - May have bugs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3Vbp3YOQ4L69"},"outputs":[],"source":["class VisualBERTFineTuner(pl.LightningModule):\n","    def __init__(self, hparams):\n","        super(VisualBERTFineTuner, self).__init__()      \n","        self.model = VisualBERTClassifier().double()\n","        self.num_labels = 2\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(768, self.num_labels)\n","\n","        self.problem_type = 'single_label_classification'\n","        self.save_hyperparameters(hparams)\n","        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","        self.output_dir = Path(self.hparams.output_dir)\n","        self.total_steps = 0\n","\n","    def is_logger(self):\n","        return self.trainer.global_rank \u003c= 0\n","    \n","        \n","    def forward(self, input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask,\n","                visual_token_type_ids, labels):\n","        loss, preds = self.model(\n","                input_ids,\n","                attention_mask=attention_mask,\n","                token_type_ids=token_type_ids,\n","                visual_embeds=visual_embeds,\n","                visual_attention_mask=visual_attention_mask,\n","                visual_token_type_ids=visual_token_type_ids,\n","                labels = labels\n","            )\n","        return loss, preds \n","\n","    # def loss(self, batch, prediction):\n","    #     loss_fct = CrossEntropyLoss()\n","    #     labels = batch['label']\n","    #     loss = loss_fct(prediction.view(-1, self.num_labels), labels.view(-1))\n","    #     return loss\n","   \n","\n","    def _step(self, batch):\n","        outputs = self(\n","            input_ids=batch[\"input_ids\"],\n","            attention_mask=batch[\"attention_mask\"],\n","            token_type_ids=batch[\"token_type_ids\"],\n","            visual_embeds=batch[\"visual_embeds\"],\n","            visual_attention_mask=batch[\"visual_attention_mask\"],\n","            visual_token_type_ids=batch[\"visual_token_type_ids\"],\n","            labels = batch['label']\n","        )\n","\n","        return outputs\n","    \n","\n","    def training_step(self, batch, batch_idx):\n","        loss, preds = self._step(batch)\n","        return loss\n","  \n","\n","    def validation_step(self, batch, batch_idx):\n","        val_loss, preds = self._step(batch)\n","        preds = torch.argmax(preds, axis=1)\n","        labels = batch[\"label\"]\n","        return {'loss': val_loss, \"preds\": preds, \"labels\": labels}\n","\n","    \n","    def validation_epoch_end(self, outputs):\n","        preds = torch.cat([x['preds'] for x in outputs]).detach().cpu().numpy()\n","        labels = torch.cat([x['labels'] for x in outputs]).detach().cpu().numpy()\n","        loss = torch.stack([x['loss'] for x in outputs]).mean()\n","        auc_score = roc_auc_score(labels, preds, average='weighted')\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.log('val_auroc', auc_score, prog_bar=True)\n","        self.log_dict(acc_metric.compute(predictions=preds, references=labels), prog_bar=True)\n","\n","\n","    def configure_optimizers(self):\n","\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.hparams.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.total_steps\n","        )\n","        scheduler = {'scheduler': scheduler, 'interval': 'step', 'frequency': 1}\n","        return [optimizer], [scheduler]\n","  \n","    # def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx,\n","    #                    closure, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n","    #     model = self.model\n","    #     if self.trainer.use_tpu:\n","    #         xm.optimizer_step(optimizer)\n","    #     else:\n","    #         optimizer.step(closure=closure)\n","    #     optimizer.zero_grad()\n","    #     torch.nn.utils.clip_grad_norm_(model.parameters(), self.hparams.max_grad_norm)\n","    #     self.lr_scheduler.step()\n","  \n","    def get_tqdm_dict(self):\n","        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","\n","        return tqdm_dict\n","    \n","    def train_dataloader(self):   \n","        train_loader = DataLoader(HatefulMemesData(df_train, self.tokenizer, self.hparams.max_input_length),\n","                                batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=2)\n","       # Calculate total steps\n","        tb_size = self.hparams.train_batch_size * max(1, self.trainer.gpus)\n","        ab_size = self.trainer.accumulate_grad_batches * float(self.trainer.max_epochs)\n","        self.total_steps = (len(train_loader.dataset) // tb_size) // ab_size\n","\n","        return train_loader\n","\n","    def val_dataloader(self):\n","        return DataLoader(HatefulMemesData(df_val, self.tokenizer, self.hparams.max_input_length),\n","                          batch_size=self.hparams.eval_batch_size, num_workers=2)\n","    \n","    def test_dataloader(self):\n","        return  DataLoader(HatefulMemesData(df_test, self.tokenizer, self.hparams.max_input_length),\n","                          batch_size=self.hparams.eval_batch_size, num_workers=2)\n","    \n","    def on_save_checkpoint(self, checkpoint):\n","        save_path = self.output_dir.joinpath(model_prefix)\n","        self.model.config.save_step = self.step_count\n","        self.model.save_pretrained(save_path)\n","        self.tokenizer.save_pretrained(save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"z2H1WD8L-KZw"},"outputs":[],"source":["# from pytorch_lightning import loggers as pl_loggers\n","# tb_logger = pl_loggers.TensorBoardLogger('logs/')\n","\n","logger = logging.getLogger(__name__)\n","class LoggingCallback(pl.Callback):\n","  def on_validation_end(self, trainer, pl_module):\n","    logger.info(\"***** Validation results *****\")\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","      # Log results\n","      for key in sorted(metrics):\n","        if key not in [\"log\", \"progress_bar\"]:\n","          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","\n","  def on_test_end(self, trainer, pl_module):\n","    logger.info(\"***** Test results *****\")\n","\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","\n","      # Log and save results to file\n","      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n","      with open(output_test_results_file, \"w\") as writer:\n","        for key in sorted(metrics):\n","          if key not in [\"log\", \"progress_bar\"]:\n","            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VnCCYhNV-7Cy"},"outputs":[],"source":["model_name = \"visualbert\"\n","token_len = 50\n","model_prefix = f\"{model_name}-{token_len}\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_2rdAUs0-Pbj"},"outputs":[],"source":["args_dict = dict(\n","    output_dir=\"\", # path to save the checkpoints\n","    max_input_length=token_len,\n","    learning_rate=1e-4,\n","    weight_decay=0.0,\n","    adam_epsilon=1e-8,\n","    warmup_steps=0,\n","    train_batch_size=4,\n","    eval_batch_size=4,\n","    num_train_epochs=5,\n","    gradient_accumulation_steps=1,\n","    n_gpu=1,\n","    resume_from_checkpoint=None, \n","    val_check_interval = 0.5, \n","    early_stop_callback=False,\n","    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n","    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n","    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n","    seed=42,\n",")\n","\n","\n","args_dict.update({'output_dir': \"./\" + model_prefix + \"_final\", 'num_train_epochs':6,\n","             'train_batch_size': 32, 'eval_batch_size': 32})\n","args = argparse.Namespace(**args_dict)\n","\n","\n","## Define Checkpoint function\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    dirpath=\"./\" + model_prefix + \"_checkpoint\", filename=model_prefix, monitor=\"accuracy\", mode=\"max\", save_top_k=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xH5bESY5vVoe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Namespace(adam_epsilon=1e-08, early_stop_callback=False, eval_batch_size=32, fp_16=False, gradient_accumulation_steps=1, learning_rate=0.0001, max_grad_norm=1.0, max_input_length=50, n_gpu=1, num_train_epochs=6, opt_level='O1', output_dir='./visualbert-50_final', resume_from_checkpoint=None, seed=42, train_batch_size=32, val_check_interval=0.5, warmup_steps=0, weight_decay=0.0)\n"]}],"source":["print(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MTjBlV4l-q_N"},"outputs":[],"source":["train_params = dict(\n","    accumulate_grad_batches=args.gradient_accumulation_steps,\n","    gpus=min(1, torch.cuda.device_count()),\n","    max_epochs=args.num_train_epochs,\n","    precision= 16 if args.fp_16 else 32,\n","    amp_level=args.opt_level,\n","    resume_from_checkpoint=args.resume_from_checkpoint,\n","    # gradient_clip_val=args.max_grad_norm,\n","    checkpoint_callback=checkpoint_callback,\n","    val_check_interval=args.val_check_interval,\n","    callbacks=[LoggingCallback()],\n","    # logger=tb_logger\n",")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dwmhgyIB-r5e"},"source":["model = VisualBERTFineTuner(args)\n","trainer = pl.Trainer(**train_params)"]},{"cell_type":"markdown","metadata":{"id":"M1x3bI6Sw6Rb"},"source":["trainer.fit(model)"]},{"cell_type":"markdown","metadata":{"id":"sAhPxMZx6kg3"},"source":["## Hyperparameter Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOB-4LmLasvz"},"outputs":[],"source":["! pip install optuna -q\n","! pip install 'ray[tune]'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ehKa09yWRBJE"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n","  \"update your install command.\", FutureWarning)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.5.0'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["import ray\n","ray.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1a8IrKkuZRy7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.10.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pyarrow!=4.0.0,\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: huggingface-hub\u003c0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: tqdm\u003e=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.61.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: fsspec\u003e=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c0.1.0-\u003edatasets) (3.0.12)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003edatasets) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2021.5.30)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.0.4)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003edatasets) (3.5.0)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2.8.1)\n","Requirement already satisfied: pytz\u003e=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2018.9)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003edatasets) (1.15.0)\n"]}],"source":["! pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ci74nEW2iYLO"},"outputs":[],"source":["import os\n","import ray\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import PopulationBasedTraining\n","from transformers import  AutoConfig, \\\n","    AutoModelForSequenceClassification, AutoTokenizer, Trainer, \\\n","     TrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6vsUnjoaklxn"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n"," \n","    predictions = np.argmax(predictions, axis=1)\n","    acc = acc_metric.compute(predictions=predictions, references=labels)\n","    # precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n","    # recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n","    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OeCfBcgqigqi"},"outputs":[],"source":["def tune_transformer( train_dataset,\n","                     test_dataset,\n","                    num_samples=8,\n","                     gpus_per_trial=0,\n","                     num_labels=5,\n","                     ray_address=None):\n","    \n","    #ray.shutdown()\n","    #ray.init(ray_address, log_to_driver=False)\n","    data_dir_name = \"./data\" \n","    data_dir = os.path.abspath(os.path.join(os.getcwd(), data_dir_name))\n","    if not os.path.exists(data_dir):\n","        os.mkdir(data_dir, 0o755)\n","\n","    # Change these as needed.\n","    model_name = \"roberta-base\" \n","\n","    config = AutoConfig.from_pretrained(\n","        model_name, num_labels=num_labels )\n","\n","    # Download and cache tokenizer, model, and features\n","    print(\"Downloading and caching Tokenizer\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    # Triggers tokenizer download to cache\n","    print(\"Downloading and caching pre-trained model\")\n","    AutoModelForSequenceClassification.from_pretrained(\n","        model_name,\n","        config=config,\n","    )\n","\n","    def get_model():\n","        return AutoModelForSequenceClassification.from_pretrained(\n","            model_name,\n","            config=config,\n","        )\n","\n","\n","    training_args = TrainingArguments(\n","        output_dir=\".\",\n","        learning_rate=1e-5,  # config\n","        do_train=True,\n","        do_eval=True,\n","        no_cuda=gpus_per_trial \u003c= 0,\n","        evaluation_strategy=\"epoch\",\n","        load_best_model_at_end=True,\n","        num_train_epochs=2,  # config\n","        max_steps=-1,\n","        per_device_train_batch_size=16,  # config\n","        per_device_eval_batch_size=16,  # config\n","        warmup_steps=0,\n","        weight_decay=0.1,  # config\n","        logging_dir=\"./logs\",\n","    )\n","\n","    training_args._n_gpu = gpus_per_trial\n","\n","    trainer = Trainer(\n","        model_init=get_model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=test_dataset,\n","        compute_metrics=compute_metrics)\n","\n","    tune_config = {\n","        \"per_device_train_batch_size\": 32,\n","        \"per_device_eval_batch_size\": 32,\n","        \"num_train_epochs\": tune.choice([2, 3, 4, 5]),\n","        \"max_steps\": 1 \n","    }\n","\n","    scheduler = PopulationBasedTraining(\n","        time_attr=\"training_iteration\",\n","        metric=\"eval_acc\",\n","        mode=\"max\",\n","        perturbation_interval=1,\n","        hyperparam_mutations={\n","            \"weight_decay\": tune.uniform(0.0, 0.3),\n","            \"learning_rate\": tune.uniform(1e-5, 5e-5),\n","            \"per_device_train_batch_size\": [16, 32, 64],\n","        })\n","\n","    reporter = CLIReporter(\n","        parameter_columns={\n","            \"weight_decay\": \"w_decay\",\n","            \"learning_rate\": \"lr\",\n","            \"per_device_train_batch_size\": \"train_bs/gpu\",\n","            \"num_train_epochs\": \"num_epochs\"\n","        },\n","        metric_columns=[\n","            \"eval_acc\", \"eval_loss\", \"epoch\", \"training_iteration\"\n","        ])\n","\n","    trainer.hyperparameter_search(\n","        hp_space=lambda _: tune_config,\n","        backend=\"ray\",\n","        n_trials=num_samples,\n","        resources_per_trial={\n","            \"cpu\": 1,\n","            \"gpu\": gpus_per_trial\n","        },\n","        scheduler=scheduler,\n","        keep_checkpoints_num=1,\n","        checkpoint_score_attr=\"training_iteration\",\n","        stop=None,\n","        progress_reporter=reporter,\n","        local_dir=\"~/ray_results/\",\n","        name=\"tune_transformer_pbt\",\n","        log_to_file=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S-uiaCxNjrKw"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-62-1eaf18a266c4\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtune_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'encoded_train_dataset' is not defined"]}],"source":["tune_transformer(encoded_train_dataset, encoded_test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JaMjFUzyYfNN"},"outputs":[],"source":["def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(\n","        'roberta-base', return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pOoJymMpYVOH"},"outputs":[],"source":["trainer = Trainer(\n","    args=args,\n","    tokenizer=tokenizer,\n","    train_dataset= encoded_train_dataset, \n","    eval_dataset=encoded_test_dataset,\n","    model_init=model_init,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F6voqTJ3gZCR"},"outputs":[],"source":["from ray.tune.schedulers import PopulationBasedTraining\n","from ray.tune import uniform\n","from random import randint\n","from ray import tune\n","\n","scheduler = PopulationBasedTraining(\n","    mode = \"max\",\n","    metric='mean_accuracy',\n","    perturbation_interval=2,\n","    hyperparam_mutations={\n","        \"weight_decay\": tune.uniform(0.0, 0.3),\n","        \"learning_rate\": tune.uniform(1e-5, 5e-5),\n","        \"per_device_train_batch_size\": tune.choice([16, 32, 64]),\n","        \"num_train_epochs\": tune.choice([2,3,4]),\n","        \"warmup_steps\":tune.choice(range(0, 500))\n","    }\n",")\n","\n","best_trial = trainer.hyperparameter_search(\n","    direction=\"maximize\",\n","    backend=\"ray\",\n","    n_trials=10,\n","    keep_checkpoints_num=1,\n","    scheduler=scheduler)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYg8q9XOlFfZ"},"outputs":[],"source":["best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-0epmcSaHC0"},"outputs":[],"source":["best_trial = trainer.hyperparameter_search(\n","    direction=\"maximize\",\n","    backend=\"ray\",\n","    # Choose among many libraries:\n","    # https://docs.ray.io/en/latest/tune/api_docs/suggestion.html\n","    search_alg=HyperOptSearch(),\n","    # Choose among schedulers:\n","    # https://docs.ray.io/en/latest/tune/api_docs/schedulers.html\n","    scheduler=AsyncHyperBand())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfvcxwkwY524"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"AugLyEd_VisualBERt_ViT_trainer.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}